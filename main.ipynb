{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bca5f545",
   "metadata": {},
   "source": [
    "# Main imports and code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "44454646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from transformers import AutoTokenizer, RobertaModel, RobertaForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "6995a9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    for i in range(num_devices):\n",
    "        device = torch.cuda.device(i)\n",
    "        total_mem = torch.cuda.get_device_properties(i).total_memory / 1024**3  # Convert to GB\n",
    "        allocated_mem = torch.cuda.memory_allocated(i) / 1024**3  # Convert to GB\n",
    "        free_mem = total_mem - allocated_mem\n",
    "        \n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"Total Memory: {total_mem:.1f}GB\")\n",
    "        print(f\"Allocated Memory: {allocated_mem:.1f}GB\")\n",
    "        print(f\"Free Memory: {free_mem:.1f}GB\")\n",
    "        \n",
    "        if free_mem < 8:\n",
    "            print(f\"Warning: GPU {i} has less than 8GB of free VRAM!\")\n",
    "        else:\n",
    "            print(f\"Using GPU {i} with {free_mem:.1f}GB free VRAM\")\n",
    "            break \n",
    "    device = torch.device(f\"cuda:{i}\")\n",
    "else:\n",
    "    print(\"Warning: No GPU devices available - running on CPU only\")\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c8e63a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0057a049",
   "metadata": {},
   "source": [
    "# Loading and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ceacee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/FacebookAI/roberta-base/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/FacebookAI/roberta-base/e2da8e2f811d1448a5b465c236feacd80ffbac7b/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/FacebookAI/roberta-base/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/FacebookAI/roberta-base/e2da8e2f811d1448a5b465c236feacd80ffbac7b/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/FacebookAI/roberta-base/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/FacebookAI/roberta-base/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "# Helper function to save predictions to an output file\n",
    "def labels2file(p, file_name):\n",
    "\twith open(f'./logs/{file_name}','w') as outf:\n",
    "\t\tfor pi in p:\n",
    "\t\t\toutf.write(','.join([str(k) for k in pi])+'\\n')\n",
    "\n",
    "def convert_label_to_binary(x):\n",
    "    return 0 if x in [0, 1] else 1\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "\n",
    "# Data loader class\n",
    "class PCLDataset(Dataset):\n",
    "    def __init__(self, text_encodings, labels):\n",
    "        self.text_encodings = text_encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.text_encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        item['country_code'] = f'dumm{idx}'\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "c3611c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 samples removed which had text length greater than threshold of 200\n"
     ]
    }
   ],
   "source": [
    "# Loading dataframe\n",
    "dataset_path = \"Dont_Patronize_Me_Trainingset\"\n",
    "split_dataset_path = f'{dataset_path}/data_splits'\n",
    "\n",
    "df = pd.read_csv(\n",
    "    f'{dataset_path}/dontpatronizeme_pcl.tsv', \n",
    "    names=[\"par_id\", \"art_id\", \"keyword\", \"country_code\", \"text\", \"label\"],\n",
    "    sep='\\t', \n",
    "    skiprows=4\n",
    ")\n",
    "\n",
    "train_csv = pd.read_csv(f'{split_dataset_path}/train_semeval_parids-labels.csv')\n",
    "dev_csv = pd.read_csv(f'{split_dataset_path}/dev_semeval_parids-labels.csv')\n",
    "test_csv = pd.read_csv(f'{split_dataset_path}/task4_test.tsv', \n",
    "    names=[\"t_id\", \"art_id\", \"keyword\", \"country_code\", \"text\"],\n",
    "    sep='\\t', \n",
    "    skiprows=4\n",
    ")\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Clean HTML tokens\n",
    "texts = df[\"text\"].to_numpy()\n",
    "rules = [(\"&amp;\", \"&\"), (\"More&gt;&gt;\", \"\"), (\"&gt;\", \"\"), (\"<h>\", \"\"), (\". .\", \".\"), (\"  \", \" \"), (\"  \", \" \")]\n",
    "counter = 0\n",
    "for (substring, replacement) in rules:\n",
    "    df.loc[:, \"text\"] = df.loc[:, \"text\"].str.replace(substring, replacement) \n",
    "\n",
    "# Remove records with abnormally long sentence length\n",
    "max_tokens_threshold = 200\n",
    "texts = df[\"text\"].to_numpy()\n",
    "good_indices = list(map(lambda a: len(a.split()) < max_tokens_threshold, texts))\n",
    "df = df[good_indices]\n",
    "print(f'{len(texts) - sum(good_indices)} samples removed which had text length greater than threshold of {max_tokens_threshold}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "aba6a4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_rebuild(data_csv):\n",
    "    rows = [] # will contain par_id, country_code, text and label\n",
    "    for idx in range(len(data_csv)):  \n",
    "        parid = data_csv[\"par_id\"][idx]\n",
    "\n",
    "        # If dataframe is empty, then sample was likely cleaned out of df\n",
    "        if df.loc[df[\"par_id\"] == parid].empty: continue\n",
    "\n",
    "        # select row from original dataset to retrieve data\n",
    "        keyword = df.loc[df[\"par_id\"] == parid].keyword.values[0]\n",
    "        country = df.loc[df[\"par_id\"] == parid].country_code.values[0]\n",
    "        text = df.loc[df[\"par_id\"]  == parid].text.values[0]\n",
    "        label = df.loc[df[\"par_id\"]  == parid].label.values[0]\n",
    "        rows.append({\n",
    "            'par_id':parid,\n",
    "            'country_code': country,\n",
    "            'community':keyword,\n",
    "            'text':text,\n",
    "            'label':label\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "train_set = dataset_rebuild(train_csv)\n",
    "train_set = train_set.sample(frac=1)\n",
    "dev_set = dataset_rebuild(dev_csv)\n",
    "test_set = test_csv\n",
    "\n",
    "# Create datasets\n",
    "train_text_encodings = tokenizer(list(train_set[\"text\"].values), truncation=True, padding=True, max_length=256)\n",
    "dev_text_encodings = tokenizer(list(dev_set[\"text\"].values), truncation=True, padding=True, max_length=256)\n",
    "test_text_encodings = tokenizer(list(test_set[\"text\"].values), truncation=True, padding=True, max_length=256)\n",
    "\n",
    "train_dataset = PCLDataset(train_text_encodings, train_set[\"label\"].to_numpy())\n",
    "dev_dataset = PCLDataset(dev_text_encodings, dev_set[\"label\"].to_numpy())\n",
    "test_dataset = PCLDataset(test_text_encodings, test_set[\"country_code\"].to_numpy())\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8f495",
   "metadata": {},
   "source": [
    "# Training baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242e2a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample negative instances\n",
    "pcldf = train_set[train_set.label==1]\n",
    "npos = len(pcldf)\n",
    "baseline_train_set = pd.concat([pcldf,train_set[train_set.label==0][:npos*2]])\n",
    "\n",
    "train_text_encodings = tokenizer(list(baseline_train_set[\"text\"].values), truncation=True, padding=True)\n",
    "print(train_text_encodings)\n",
    "dev_text_encodings = tokenizer(list(dev_set[\"text\"].values), truncation=True, padding=True)\n",
    "\n",
    "# Create downsampled training datasets\n",
    "baseline_train_dataset = PCLDataset(train_text_encodings, baseline_train_set[\"label\"].to_numpy())\n",
    "\n",
    "# Create dataloaders\n",
    "baseline_train_loader = DataLoader(baseline_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-base\", num_labels=2).to(device)\n",
    "optimiser = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "epoch = 10\n",
    "num_warmup_steps = epoch * len(baseline_train_loader) * 0.1 \n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimiser, num_warmup_steps=num_warmup_steps, num_training_steps= (epoch * len(baseline_train_loader))\n",
    ")\n",
    "\n",
    "model.train()\n",
    "for e in range(epoch):\n",
    "    for i, batch in enumerate(baseline_train_loader):\n",
    "        torch.mps.empty_cache() # Not necessary if not using MPS\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        print(input_ids.shape)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        logits = model(input_ids, attention_mask=attention_mask).logits\n",
    "        loss = criterion(softmax(logits), labels)\n",
    "\n",
    "        if ((i + 1) % 6 == 0):\n",
    "            print(f'epoch: {e}, batch: {i + 1}, loss: {loss:.5f}, lr: {optimiser.param_groups[0]['lr']:.7f}')\n",
    "\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        scheduler.step()\n",
    "\n",
    "# Save checkpoint\n",
    "state = {\n",
    "    'model_state_dict': model.state_dict()\n",
    "}\n",
    "torch.save(state, f'./baseline_models/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "0e1c507a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/FacebookAI/roberta-base/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/FacebookAI/roberta-base/e2da8e2f811d1448a5b465c236feacd80ffbac7b/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/FacebookAI/roberta-base/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/FacebookAI/roberta-base/e2da8e2f811d1448a5b465c236feacd80ffbac7b/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/FacebookAI/roberta-base/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/FacebookAI/roberta-base/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/FacebookAI/roberta-base/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/FacebookAI/roberta-base/e2da8e2f811d1448a5b465c236feacd80ffbac7b/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/FacebookAI/roberta-base/resolve/main/model.safetensors \"HTTP/1.1 302 Found\"\n",
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 1818.79it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "\u001b[1mRobertaForSequenceClassification LOAD REPORT\u001b[0m from: FacebookAI/roberta-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "classifier.dense.weight         | MISSING    | \n",
      "classifier.dense.bias           | MISSING    | \n",
      "classifier.out_proj.bias        | MISSING    | \n",
      "classifier.out_proj.weight      | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed iteration 0\n",
      "completed iteration 100\n",
      "completed iteration 200\n",
      "completed iteration 300\n",
      "completed iteration 400\n",
      "completed iteration 500\n",
      "completed iteration 600\n",
      "completed iteration 700\n",
      "completed iteration 800\n",
      "completed iteration 900\n",
      "completed iteration 1000\n",
      "completed iteration 1100\n",
      "completed iteration 1200\n",
      "completed iteration 1300\n",
      "completed iteration 1400\n",
      "completed iteration 1500\n",
      "completed iteration 1600\n",
      "completed iteration 1700\n",
      "completed iteration 1800\n",
      "completed iteration 1900\n",
      "completed iteration 2000\n",
      "Evaluation finished!\n",
      "\n",
      "[[1407  486]\n",
      " [ 133   66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.74      0.82      1893\n",
      "           1       0.12      0.33      0.18       199\n",
      "\n",
      "    accuracy                           0.70      2092\n",
      "   macro avg       0.52      0.54      0.50      2092\n",
      "weighted avg       0.84      0.70      0.76      2092\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-base\").to(device)\n",
    "saved_state = torch.load(\"./baseline_models/model.pth\")\n",
    "model.load_state_dict(saved_state['model_state_dict'])\n",
    "\n",
    "predictions, labels = [], []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for index, row in dev_set.iterrows():\n",
    "        labels.append(convert_label_to_binary(row.label))\n",
    "        inputs = tokenizer(row.text, return_tensors=\"pt\").to(device)\n",
    "        logits = model(**inputs).logits\n",
    "        predictions.append(logits.argmax(dim=1)[0].cpu())\n",
    "\n",
    "        if (index % 100 == 0):\n",
    "            print(f'completed iteration {index}')\n",
    "print(\"Evaluation finished!\\n\")\n",
    "\n",
    "# Reformat data\n",
    "predictions = np.array(predictions)\n",
    "labels = np.array(labels)\n",
    "cm = confusion_matrix(labels, predictions)\n",
    "\n",
    "# Print confustion matrix and metrics\n",
    "print(cm)\n",
    "print(classification_report(labels, predictions))\n",
    "\n",
    "# Plot confustion matrix\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in \"01\"],\n",
    "                  columns = [i for i in \"01\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, annot=True).set(xlabel = 'predictions', ylabel = 'ground truth')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5661bc90",
   "metadata": {},
   "source": [
    "# Implementing my approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "97a9bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, latent_encoding_size = 256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = RobertaModel.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "\n",
    "        self.sequence_encoding_mlp = nn.Sequential(\n",
    "            nn.Linear(768, 512),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, latent_encoding_size)\n",
    "        )\n",
    "\n",
    "        self.geo_embedding_mlp = nn.Sequential(\n",
    "            nn.Linear(20, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, latent_encoding_size)\n",
    "        )\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(256, 5),\n",
    "            nn.BatchNorm1d(5),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, geo_tokens):\n",
    "        # Get geographical \n",
    "        geo_embedding = self.geo_embedding_mlp(self.encode_geoloc(geo_tokens))\n",
    "\n",
    "        # Encode text tokens\n",
    "        encoding = self.encoder(input_ids, attention_mask).last_hidden_state[:, 0:]\n",
    "        encoding = self.sequence_encoding_mlp(encoding)\n",
    "\n",
    "        # MLP layer\n",
    "        x = encoding + geo_embedding\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.output(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def encode_geoloc(self, country_encodings):\n",
    "        results, one_hot_encoding = [], ['au','bd','ca','gb','gh','hk','ie','in','jm','ke','lk','my','ng','nz','ph','pk','sg','tz','us','za']\n",
    "        for c in country_encodings:\n",
    "            results.append([1.0 if (one_hot_encoding.index(c) == i) else 0.0 for i in range(len(one_hot_encoding))])\n",
    "\n",
    "        return results\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "46637f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/FacebookAI/roberta-base/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/FacebookAI/roberta-base/e2da8e2f811d1448a5b465c236feacd80ffbac7b/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/FacebookAI/roberta-base/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/FacebookAI/roberta-base/e2da8e2f811d1448a5b465c236feacd80ffbac7b/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/FacebookAI/roberta-base/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/FacebookAI/roberta-base/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/FacebookAI/roberta-base/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/FacebookAI/roberta-base/e2da8e2f811d1448a5b465c236feacd80ffbac7b/config.json \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD https://huggingface.co/FacebookAI/roberta-base/resolve/main/model.safetensors \"HTTP/1.1 302 Found\"\n",
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 2037.61it/s, Materializing param=encoder.layer.11.output.dense.weight]              \n",
      "\u001b[1mRobertaModel LOAD REPORT\u001b[0m from: FacebookAI/roberta-base\n",
      "Key                             | Status     | \n",
      "--------------------------------+------------+-\n",
      "lm_head.layer_norm.bias         | UNEXPECTED | \n",
      "lm_head.dense.bias              | UNEXPECTED | \n",
      "lm_head.bias                    | UNEXPECTED | \n",
      "lm_head.layer_norm.weight       | UNEXPECTED | \n",
      "roberta.embeddings.position_ids | UNEXPECTED | \n",
      "lm_head.dense.weight            | UNEXPECTED | \n",
      "pooler.dense.weight             | MISSING    | \n",
      "pooler.dense.bias               | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input_ids', 'attention_mask', 'labels', 'country_code']\n",
      "torch.Size([16, 225])\n",
      "torch.Size([16, 225])\n",
      "torch.Size([16])\n",
      "[('dumm0', 'dumm0', 'dumm0', 'dumm0', 'dumm0', 'dumm0', 'dumm0', 'dumm0', 'dumm0', 'dumm0', 'dumm0', 'dumm0', 'dumm0', 'dumm0', 'dumm0', 'dumm0'), ('dumm1', 'dumm1', 'dumm1', 'dumm1', 'dumm1', 'dumm1', 'dumm1', 'dumm1', 'dumm1', 'dumm1', 'dumm1', 'dumm1', 'dumm1', 'dumm1', 'dumm1', 'dumm1'), ('dumm2', 'dumm2', 'dumm2', 'dumm2', 'dumm2', 'dumm2', 'dumm2', 'dumm2', 'dumm2', 'dumm2', 'dumm2', 'dumm2', 'dumm2', 'dumm2', 'dumm2', 'dumm2'), ('dumm3', 'dumm3', 'dumm3', 'dumm3', 'dumm3', 'dumm3', 'dumm3', 'dumm3', 'dumm3', 'dumm3', 'dumm3', 'dumm3', 'dumm3', 'dumm3', 'dumm3', 'dumm3'), ('dumm4', 'dumm4', 'dumm4', 'dumm4', 'dumm4', 'dumm4', 'dumm4', 'dumm4', 'dumm4', 'dumm4', 'dumm4', 'dumm4', 'dumm4', 'dumm4', 'dumm4', 'dumm4'), ('dumm5', 'dumm5', 'dumm5', 'dumm5', 'dumm5', 'dumm5', 'dumm5', 'dumm5', 'dumm5', 'dumm5', 'dumm5', 'dumm5', 'dumm5', 'dumm5', 'dumm5', 'dumm5'), ('dumm6', 'dumm6', 'dumm6', 'dumm6', 'dumm6', 'dumm6', 'dumm6', 'dumm6', 'dumm6', 'dumm6', 'dumm6', 'dumm6', 'dumm6', 'dumm6', 'dumm6', 'dumm6'), ('dumm7', 'dumm7', 'dumm7', 'dumm7', 'dumm7', 'dumm7', 'dumm7', 'dumm7', 'dumm7', 'dumm7', 'dumm7', 'dumm7', 'dumm7', 'dumm7', 'dumm7', 'dumm7'), ('dumm8', 'dumm8', 'dumm8', 'dumm8', 'dumm8', 'dumm8', 'dumm8', 'dumm8', 'dumm8', 'dumm8', 'dumm8', 'dumm8', 'dumm8', 'dumm8', 'dumm8', 'dumm8'), ('dumm9', 'dumm9', 'dumm9', 'dumm9', 'dumm9', 'dumm9', 'dumm9', 'dumm9', 'dumm9', 'dumm9', 'dumm9', 'dumm9', 'dumm9', 'dumm9', 'dumm9', 'dumm9'), ('dumm10', 'dumm10', 'dumm10', 'dumm10', 'dumm10', 'dumm10', 'dumm10', 'dumm10', 'dumm10', 'dumm10', 'dumm10', 'dumm10', 'dumm10', 'dumm10', 'dumm10', 'dumm10'), ('dumm11', 'dumm11', 'dumm11', 'dumm11', 'dumm11', 'dumm11', 'dumm11', 'dumm11', 'dumm11', 'dumm11', 'dumm11', 'dumm11', 'dumm11', 'dumm11', 'dumm11', 'dumm11'), ('dumm12', 'dumm12', 'dumm12', 'dumm12', 'dumm12', 'dumm12', 'dumm12', 'dumm12', 'dumm12', 'dumm12', 'dumm12', 'dumm12', 'dumm12', 'dumm12', 'dumm12', 'dumm12'), ('dumm13', 'dumm13', 'dumm13', 'dumm13', 'dumm13', 'dumm13', 'dumm13', 'dumm13', 'dumm13', 'dumm13', 'dumm13', 'dumm13', 'dumm13', 'dumm13', 'dumm13', 'dumm13'), ('dumm14', 'dumm14', 'dumm14', 'dumm14', 'dumm14', 'dumm14', 'dumm14', 'dumm14', 'dumm14', 'dumm14', 'dumm14', 'dumm14', 'dumm14', 'dumm14', 'dumm14', 'dumm14'), ('dumm15', 'dumm15', 'dumm15', 'dumm15', 'dumm15', 'dumm15', 'dumm15', 'dumm15', 'dumm15', 'dumm15', 'dumm15', 'dumm15', 'dumm15', 'dumm15', 'dumm15', 'dumm15')]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MyModel.forward() missing 1 required positional argument: 'geo_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[309]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(batch[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m].shape)\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(batch[\u001b[33m'\u001b[39m\u001b[33mcountry_code\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m outputs = \u001b[43mnew_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m input_embeddings = outputs.hidden_states[\u001b[32m0\u001b[39m]\n\u001b[32m     30\u001b[39m labels = batch[\u001b[33m'\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m'\u001b[39m].to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SchoolStuff/IC/Year3/60035NaturalLanguageProcessing/CW/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/SchoolStuff/IC/Year3/60035NaturalLanguageProcessing/CW/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mTypeError\u001b[39m: MyModel.forward() missing 1 required positional argument: 'geo_tokens'"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-base\")\n",
    "\n",
    "new_model = MyModel().to(device)\n",
    "optimiser = torch.optim.AdamW(new_model.parameters(), lr=2e-4, weight_decay=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "epoch = 10\n",
    "num_warmup_steps = epoch * len(train_loader) * 0.1 \n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimiser, num_warmup_steps=num_warmup_steps, num_training_steps= (epoch * len(train_loader))\n",
    ")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "new_model.train()\n",
    "for e in range(epoch):\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        torch.mps.empty_cache() # Not necessary if not using MPS\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        print([k for k in batch])\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        print(input_ids.shape)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        print(attention_mask.shape)\n",
    "        print(batch['labels'].shape)\n",
    "        print(batch['country_code'])\n",
    "        outputs = new_model(input_ids, attention_mask)\n",
    "        input_embeddings = outputs.hidden_states[0]\n",
    "        \n",
    "        labels = batch['labels'].to(device)\n",
    "        loss = criterion(softmax(logits), labels)\n",
    "\n",
    "        if ((i + 1) % 6 == 0):\n",
    "            print(f'epoch: {e}, batch: {i + 1}, loss: {loss:.5f}, lr: {optimiser.param_groups[0]['lr']:.7f}')\n",
    "\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        break\n",
    "\n",
    "# # Save checkpoint\n",
    "# state = {\n",
    "#     'model_state_dict': new_model.state_dict()\n",
    "# }\n",
    "# torch.save(state, f'./new_models/model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
